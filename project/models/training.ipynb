{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from autosklearn.metrics import mean_absolute_error as auto_mean_absolute_error\n",
    "from autosklearn.regression import AutoSklearnRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando as funções de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_categorical_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = df.select_dtypes(exclude='number').columns\n",
    "    for cols in cols:\n",
    "        df[cols] = df[cols].astype('category').cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(df_train: pd.DataFrame, df_val: pd.DataFrame, test_name: str) -> None:\n",
    "    print(f\"LINEAR REGRESSION: {test_name:^20}\")\n",
    "\n",
    "    df_train = remove_categorical_columns(df_train).dropna()\n",
    "    df_val = remove_categorical_columns(df_val).dropna()\n",
    "\n",
    "    X_train, y_train = df_train.drop(columns=[\"Next Week's Deaths\"]), df_train[\"Next Week's Deaths\"]\n",
    "    X_val, y_val = df_val.drop(columns=[\"Next Week's Deaths\"]), df_val[\"Next Week's Deaths\"]\n",
    "\n",
    "    LinearRegressionParams = {\n",
    "        \"fit_intercept\": [True, False],\n",
    "        \"copy_X\": [True, False]\n",
    "    }\n",
    "\n",
    "    def objective(trial):\n",
    "        model_params = {key: trial.suggest_categorical(key, values) for key, values in LinearRegressionParams.items()}\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            model = LinearRegression(**model_params, n_jobs=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Fazer previsões e calcular o erro quadrático médio\n",
    "            y_pred = model.predict(X_val)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "            # Registrar os parâmetros e métricas no MLflow\n",
    "            for key, value in model_params.items():\n",
    "                mlflow.log_param(key, value)\n",
    "\n",
    "            mlflow.log_metric('mse', mse)\n",
    "            mlflow.sklearn.log_model(model, 'model')\n",
    "            return mse\n",
    "\n",
    "    # Configurar e executar a otimização do Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    print('Melhores hiperparâmetros:', study.best_params)\n",
    "    print('Melhor valor objetivo:', study.best_value)\n",
    "\n",
    "    study.trials_dataframe().to_csv(f'../data/LinearRegressionParams_{test_name}_study.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge(df_train: pd.DataFrame, df_val: pd.DataFrame, test_name: str) -> None:\n",
    "    print(f\"RIDGE: {test_name:^20}\")\n",
    "\n",
    "    df_train = remove_categorical_columns(df_train).dropna()\n",
    "    df_val = remove_categorical_columns(df_val).dropna()\n",
    "\n",
    "    X_train, y_train = df_train.drop(columns=[\"Next Week's Deaths\"]), df_train[\"Next Week's Deaths\"]\n",
    "    X_val, y_val = df_val.drop(columns=[\"Next Week's Deaths\"]), df_val[\"Next Week's Deaths\"]\n",
    "\n",
    "    RidgeRegressionParams = {\n",
    "        \"alpha\": [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100, 1000],\n",
    "        \"fit_intercept\": [True, False],\n",
    "        \"copy_X\": [True, False],\n",
    "        \"solver\": [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]\n",
    "    }\n",
    "\n",
    "    def objective(trial):\n",
    "        model_params = {key: trial.suggest_categorical(key, values) for key, values in RidgeRegressionParams.items()}\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            model = Ridge(**model_params, random_state=42, positive=False)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Fazer previsões e calcular o erro quadrático médio\n",
    "            y_pred = model.predict(X_val)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "            # Registrar os parâmetros e métricas no MLflow\n",
    "            for key, value in model_params.items():\n",
    "                mlflow.log_param(key, value)\n",
    "\n",
    "            mlflow.log_metric('mse', mse)\n",
    "            mlflow.sklearn.log_model(model, 'model')\n",
    "\n",
    "            return mse\n",
    "\n",
    "    # Configurar e executar a otimização do Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    print('Melhores hiperparâmetros:', study.best_params)\n",
    "    print('Melhor valor objetivo:', study.best_value)\n",
    "\n",
    "    study.trials_dataframe().to_csv(f'../data/Ridge_{test_name}_study.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVR(df_train: pd.DataFrame, df_val: pd.DataFrame, test_name: str) -> None:\n",
    "    print(f\"SVR: {test_name:^20}\")\n",
    "\n",
    "    df_train = remove_categorical_columns(df_train).dropna()\n",
    "    df_val = remove_categorical_columns(df_val).dropna()\n",
    "\n",
    "    X_train, y_train = df_train.drop(columns=[\"Next Week's Deaths\"]), df_train[\"Next Week's Deaths\"]\n",
    "    X_val, y_val = df_val.drop(columns=[\"Next Week's Deaths\"]), df_val[\"Next Week's Deaths\"]\n",
    "\n",
    "    SVRParams = {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"kernel\": [\"linear\", \"rbf\"],\n",
    "        \"degree\": [2, 3, 5],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "        \"coef0\": [0.0, 0.5, 1.0, 5.0]\n",
    "    }\n",
    "\n",
    "    def objective(trial):\n",
    "        model_params = {key: trial.suggest_categorical(key, values) for key, values in SVRParams.items()}\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            # Limitando pois é um treinamento demorado\n",
    "            model = SVR(**model_params, max_iter=1000)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Fazer previsões e calcular o erro quadrático médio\n",
    "            y_pred = model.predict(X_val)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "            # Registrar os parâmetros e métricas no MLflow\n",
    "            for key, value in model_params.items():\n",
    "                mlflow.log_param(key, value)\n",
    "\n",
    "            mlflow.log_metric('mse', mse)\n",
    "            mlflow.sklearn.log_model(model, 'model')\n",
    "            return mse\n",
    "\n",
    "    # Configurar e executar a otimização do Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    print('Melhores hiperparâmetros:', study.best_params)\n",
    "    print('Melhor valor objetivo:', study.best_value)\n",
    "\n",
    "    study.trials_dataframe().to_csv(f'../data/SVR_{test_name}_study.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RandomForestRegressor(df_train: pd.DataFrame, df_val: pd.DataFrame, test_name: str) -> None:\n",
    "    print(f\"RANDOM FOREST: {test_name:^20}\")\n",
    "\n",
    "    df_train = remove_categorical_columns(df_train).dropna()\n",
    "    df_val = remove_categorical_columns(df_val).dropna()\n",
    "\n",
    "    X_train, y_train = df_train.drop(columns=[\"Next Week's Deaths\"]), df_train[\"Next Week's Deaths\"]\n",
    "    X_val, y_val = df_val.drop(columns=[\"Next Week's Deaths\"]), df_val[\"Next Week's Deaths\"]\n",
    "\n",
    "    RandomForestRegressorParams = {\n",
    "        \"n_estimators\": [10, 50, 100, 200, 500],\n",
    "        \"criterion\": ['absolute_error', 'squared_error', 'friedman_mse'],\n",
    "        \"max_depth\": [None, 5, 10, 20, 50],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "        \"bootstrap\": [True, False]\n",
    "    }\n",
    "\n",
    "    def objective(trial):\n",
    "        model_params = {key: trial.suggest_categorical(key, values) for key, values in RandomForestRegressorParams.items()}\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            model = RandomForestRegressor(**model_params, n_jobs=-1, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Fazer previsões e calcular o erro quadrático médio\n",
    "            y_pred = model.predict(X_val)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "            # Registrar os parâmetros e métricas no MLflow\n",
    "            for key, value in model_params.items():\n",
    "                mlflow.log_param(key, value)\n",
    "\n",
    "            mlflow.log_metric('mse', mse)\n",
    "            mlflow.sklearn.log_model(model, 'model')\n",
    "            return mse\n",
    "\n",
    "    # Configurar e executar a otimização do Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    print('Melhores hiperparâmetros:', study.best_params)\n",
    "    print('Melhor valor objetivo:', study.best_value)\n",
    "\n",
    "    study.trials_dataframe().to_csv(f'../data/RandomForestRegressor_{test_name}_study.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"df_preprocessed\",\n",
    "    \"df_preprocessed_normalized\",\n",
    "    \"df\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR REGRESSION:   df_preprocessed   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'fit_intercept': False, 'copy_X': False}\n",
      "Melhor valor objetivo: 4752737.142530321\n",
      "RIDGE:   df_preprocessed   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.27367e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.27367e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.27367e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.27367e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.3888e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.86197e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54734e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'alpha': 0.001, 'fit_intercept': True, 'copy_X': False, 'solver': 'svd'}\n",
      "Melhor valor objetivo: 4752938.007250519\n",
      "RANDOM FOREST:   df_preprocessed   \n",
      "Melhores hiperparâmetros: {'n_estimators': 200, 'criterion': 'friedman_mse', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}\n",
      "Melhor valor objetivo: 421224.5297782511\n",
      "LINEAR REGRESSION: df_preprocessed_normalized\n",
      "Melhores hiperparâmetros: {'fit_intercept': True, 'copy_X': True}\n",
      "Melhor valor objetivo: 0.1142174982924279\n",
      "RIDGE: df_preprocessed_normalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'alpha': 0.001, 'fit_intercept': True, 'copy_X': True, 'solver': 'svd'}\n",
      "Melhor valor objetivo: 0.11420992765267211\n",
      "SVR: df_preprocessed_normalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'C': 10, 'kernel': 'rbf', 'degree': 2, 'gamma': 'auto', 'coef0': 0.0}\n",
      "Melhor valor objetivo: 0.04854253148412284\n",
      "RANDOM FOREST: df_preprocessed_normalized\n",
      "Melhores hiperparâmetros: {'n_estimators': 50, 'criterion': 'absolute_error', 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}\n",
      "Melhor valor objetivo: 0.01614020360164839\n",
      "LINEAR REGRESSION:          df         \n",
      "Melhores hiperparâmetros: {'fit_intercept': True, 'copy_X': True}\n",
      "Melhor valor objetivo: 1070991.7884971937\n",
      "RIDGE:          df         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.30156e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.4004e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41006e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41006e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41006e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41991e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41991e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41991e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.3174e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.37583e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41991e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41991e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41991e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41991e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.3174e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.37583e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.40022e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41991e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41991e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.5973e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.5973e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.5973e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.5973e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'alpha': 10, 'fit_intercept': True, 'copy_X': False, 'solver': 'cholesky'}\n",
      "Melhor valor objetivo: 1070846.4398777047\n",
      "RANDOM FOREST:          df         \n",
      "Melhores hiperparâmetros: {'n_estimators': 10, 'criterion': 'friedman_mse', 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}\n",
      "Melhor valor objetivo: 198043.68385618663\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    for i in [\"train\", \"val\", \"test\"]:\n",
    "        df = pd.read_csv(f\"../data/{dataset}_{i}.csv\")\n",
    "        if i == \"train\":\n",
    "            df_train = df\n",
    "        elif i == \"val\":\n",
    "            df_val = df\n",
    "        else:\n",
    "            df_test = df\n",
    "    train_linear_regression(df_train, df_val, dataset)\n",
    "    train_ridge(df_train, df_val, dataset)\n",
    "    if \"normalized\" in dataset:\n",
    "        train_SVR(df_train, df_val, dataset)\n",
    "    train_RandomForestRegressor(df_train, df_val, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando as os melhores resultados dos modelos, em geral, pode-se descartar a solução não normalizada.\n",
    "O melhor modelo de cada algorítmo foi:\n",
    "\n",
    " - Linear regression:\n",
    "    - Melhores hiperparâmetros: {'fit_intercept': True, 'copy_X': True}\n",
    "    - Melhor valor objetivo: 0.1142174982924279\n",
    " - Ridge:\n",
    "    - Melhores hiperparâmetros: {'alpha': 0.001, 'fit_intercept': True, 'copy_X': True, 'solver': 'svd'}\n",
    "    - Melhor valor objetivo: 0.11420992765267211\n",
    " - SVR:\n",
    "    - Melhores hiperparâmetros: {'C': 10, 'kernel': 'rbf', 'degree': 2, 'gamma': 'auto', 'coef0': 0.0}\n",
    "    - Melhor valor objetivo: 0.04854253148412284\n",
    " - Random Forest:\n",
    "    - Melhores hiperparâmetros: {'n_estimators': 50, 'criterion': 'absolute_error', 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}\n",
    "    - Melhor valor objetivo: 0.01614020360164839"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escolhendo o Melhor modelo pelo conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/df_preprocessed_normalized_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/df_preprocessed_normalized_test.csv\")\n",
    "df_val = pd.read_csv(\"../data/df_preprocessed_normalized_val.csv\")\n",
    "\n",
    "df_train = remove_categorical_columns(df_train).dropna()\n",
    "df_test = remove_categorical_columns(df_test).dropna()\n",
    "df_val = remove_categorical_columns(df_val).dropna()\n",
    "\n",
    "X_train, y_train = df_train.drop(columns=[\"Next Week's Deaths\"]), df_train[\"Next Week's Deaths\"]\n",
    "X_test, y_test = df_test.drop(columns=[\"Next Week's Deaths\"]), df_test[\"Next Week's Deaths\"]\n",
    "X_val, y_val = df_val.drop(columns=[\"Next Week's Deaths\"]), df_val[\"Next Week's Deaths\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10834622013794715, 0.09308352840682599)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LinearRegression(**{'fit_intercept': True, 'copy_X': True}, n_jobs=-1)\n",
    "lr_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train,y_val]))\n",
    "y_pred = lr_model.predict(X_val)\n",
    "lr_mse_val = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "lr_mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "lr_mse_val, lr_mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro no treinamento do Linear Regression foi de aproximadamente 10.83% e no conjunto de teste foi de 9.3%, o que sugere uma baixa variância mas um alto viés, o que significa que essa não é uma boa arquitetura para resolver esse problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10833588599742265, 0.09307724632163433)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = Ridge(**{'alpha': 0.001, 'fit_intercept': True, 'copy_X': True, 'solver': 'svd'}, random_state=42)\n",
    "ridge_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train,y_val]))\n",
    "y_pred = ridge_model.predict(X_val)\n",
    "ridge_mse_val = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "ridge_mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "ridge_mse_val, ridge_mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro no treinamento do Ridge foi de aproximadamente 10.83% e no conjunto de teste foi de 9.3%, o que sugere uma baixa variância mas um alto viés, o que significa que essa não é uma boa arquitetura para resolver esse problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0065046427786657045, 0.01501670629868387)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model = SVR(**{'C': 10, 'kernel': 'rbf', 'degree': 2, 'gamma': 'auto', 'coef0': 0.0})\n",
    "svr_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train,y_val]))\n",
    "y_pred = svr_model.predict(X_val)\n",
    "svr_mse_val = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "y_pred = svr_model.predict(X_test)\n",
    "svr_mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "svr_mse_val, svr_mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro no treinamento do SVR foi de aproximadamente 0.65% e no conjunto de teste foi de 1.5%, o que sugere uma baixa variância mas um baixo viés, o que significa que essa é uma boa arquitetura para resolver esse problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0017692880033518923, 0.014466576904208071)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(**{'n_estimators': 50, 'criterion': 'absolute_error', 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train,y_val]))\n",
    "y_pred = rf_model.predict(X_val)\n",
    "rf_mse_val = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "rf_mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rf_mse_val, rf_mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro no treinamento do Random Forest foi de aproximadamente 0.17% e no conjunto de teste foi de 1.4%, o que sugere uma baixa variância mas um baixo viés, o que significa que essa é uma boa arquitetura para resolver esse problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto o Random Forest quanto o SVR possuem boas perfomances e podem resolver o problema, usarei o auto-sklearn agora para tentar encontrar um modelo melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] [2024-07-04 19:45:07,642:Client-AutoML(1):0f13829c-3a57-11ef-b4d2-26e9cfab4ad5] (' Dummy prediction failed with run state StatusType.CRASHED and additional output: {\\'error\\': \\'Result queue is empty\\', \\'exit_status\\': \"<class \\'pynisher.limit_function_call.AnythingException\\'>\", \\'subprocess_stdout\\': \\'\\', \\'subprocess_stderr\\': \\'Process pynisher function call:\\\\nTraceback (most recent call last):\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\\\\n    self.run()\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\\\\n    self._target(*self._args, **self._kwargs)\\\\n  File \"/opt/homebrew/lib/python3.11/site-packages/pynisher/limit_function_call.py\", line 108, in subprocess_func\\\\n    resource.setrlimit(resource.RLIMIT_AS, (mem_in_b, mem_in_b))\\\\nValueError: current limit exceeds maximum limit\\\\n\\', \\'exitcode\\': 1, \\'configuration_origin\\': \\'DUMMY\\'}.',)\n",
      "[ERROR] [2024-07-04 19:45:07,642:Client-AutoML(1):0f13829c-3a57-11ef-b4d2-26e9cfab4ad5] (' Dummy prediction failed with run state StatusType.CRASHED and additional output: {\\'error\\': \\'Result queue is empty\\', \\'exit_status\\': \"<class \\'pynisher.limit_function_call.AnythingException\\'>\", \\'subprocess_stdout\\': \\'\\', \\'subprocess_stderr\\': \\'Process pynisher function call:\\\\nTraceback (most recent call last):\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\\\\n    self.run()\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\\\\n    self._target(*self._args, **self._kwargs)\\\\n  File \"/opt/homebrew/lib/python3.11/site-packages/pynisher/limit_function_call.py\", line 108, in subprocess_func\\\\n    resource.setrlimit(resource.RLIMIT_AS, (mem_in_b, mem_in_b))\\\\nValueError: current limit exceeds maximum limit\\\\n\\', \\'exitcode\\': 1, \\'configuration_origin\\': \\'DUMMY\\'}.',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/autosklearn/automl.py\", line 765, in fit\n",
      "    self._do_dummy_prediction()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/autosklearn/automl.py\", line 489, in _do_dummy_prediction\n",
      "    raise ValueError(msg)\n",
      "ValueError: (' Dummy prediction failed with run state StatusType.CRASHED and additional output: {\\'error\\': \\'Result queue is empty\\', \\'exit_status\\': \"<class \\'pynisher.limit_function_call.AnythingException\\'>\", \\'subprocess_stdout\\': \\'\\', \\'subprocess_stderr\\': \\'Process pynisher function call:\\\\nTraceback (most recent call last):\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\\\\n    self.run()\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\\\\n    self._target(*self._args, **self._kwargs)\\\\n  File \"/opt/homebrew/lib/python3.11/site-packages/pynisher/limit_function_call.py\", line 108, in subprocess_func\\\\n    resource.setrlimit(resource.RLIMIT_AS, (mem_in_b, mem_in_b))\\\\nValueError: current limit exceeds maximum limit\\\\n\\', \\'exitcode\\': 1, \\'configuration_origin\\': \\'DUMMY\\'}.',)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "(' Dummy prediction failed with run state StatusType.CRASHED and additional output: {\\'error\\': \\'Result queue is empty\\', \\'exit_status\\': \"<class \\'pynisher.limit_function_call.AnythingException\\'>\", \\'subprocess_stdout\\': \\'\\', \\'subprocess_stderr\\': \\'Process pynisher function call:\\\\nTraceback (most recent call last):\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\\\\n    self.run()\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\\\\n    self._target(*self._args, **self._kwargs)\\\\n  File \"/opt/homebrew/lib/python3.11/site-packages/pynisher/limit_function_call.py\", line 108, in subprocess_func\\\\n    resource.setrlimit(resource.RLIMIT_AS, (mem_in_b, mem_in_b))\\\\nValueError: current limit exceeds maximum limit\\\\n\\', \\'exitcode\\': 1, \\'configuration_origin\\': \\'DUMMY\\'}.',)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoSklearnRegressor(\n\u001b[1;32m      2\u001b[0m     time_left_for_this_task\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m180\u001b[39m,\n\u001b[1;32m      3\u001b[0m     per_run_time_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m      4\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/autosklearn/estimators.py:1587\u001b[0m, in \u001b[0;36mAutoSklearnRegressor.fit\u001b[0;34m(self, X, y, X_test, y_test, feat_type, dataset_name)\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegression with data of type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot supported. Supported types are \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target_type, supported_types)\n\u001b[1;32m   1583\u001b[0m     )\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;66;03m# Fit is supposed to be idempotent!\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;66;03m# But not if we use share_mode.\u001b[39;00m\n\u001b[0;32m-> 1587\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeat_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeat_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/autosklearn/estimators.py:540\u001b[0m, in \u001b[0;36mAutoSklearnEstimator.fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoml_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoml_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_automl()\n\u001b[0;32m--> 540\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoml_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/autosklearn/automl.py:2394\u001b[0m, in \u001b[0;36mAutoMLRegressor.fit\u001b[0;34m(self, X, y, X_test, y_test, feat_type, dataset_name, only_return_configuration_space, load_models)\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m   2384\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2385\u001b[0m     X: SUPPORTED_FEAT_TYPES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2392\u001b[0m     load_models: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2393\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AutoMLRegressor:\n\u001b[0;32m-> 2394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2396\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeat_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_return_configuration_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_return_configuration_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_classification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/autosklearn/automl.py:962\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[0;34m(self, X, y, task, X_test, y_test, feat_type, dataset_name, only_return_configuration_space, load_models, is_classification)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;66;03m# This will be called before the _fit_cleanup\u001b[39;00m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mexception(e)\n\u001b[0;32m--> 962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_cleanup()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/autosklearn/automl.py:765\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[0;34m(self, X, y, task, X_test, y_test, feat_type, dataset_name, only_return_configuration_space, load_models, is_classification)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopwatch\u001b[38;5;241m.\u001b[39mtime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDummy predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_run \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_dummy_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;66;03m# == RUN ensemble builder\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;66;03m# Do this before calculating the meta-features to make sure that the\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;66;03m# dummy predictions are actually included in the ensemble even if\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# calculating the meta-features takes very long\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopwatch\u001b[38;5;241m.\u001b[39mtime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun Ensemble Builder\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/autosklearn/automl.py:489\u001b[0m, in \u001b[0;36mAutoML._do_dummy_prediction\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    484\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Dummy prediction failed with run state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m additional output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    486\u001b[0m         )\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39merror(msg)\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: (' Dummy prediction failed with run state StatusType.CRASHED and additional output: {\\'error\\': \\'Result queue is empty\\', \\'exit_status\\': \"<class \\'pynisher.limit_function_call.AnythingException\\'>\", \\'subprocess_stdout\\': \\'\\', \\'subprocess_stderr\\': \\'Process pynisher function call:\\\\nTraceback (most recent call last):\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\\\\n    self.run()\\\\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\\\\n    self._target(*self._args, **self._kwargs)\\\\n  File \"/opt/homebrew/lib/python3.11/site-packages/pynisher/limit_function_call.py\", line 108, in subprocess_func\\\\n    resource.setrlimit(resource.RLIMIT_AS, (mem_in_b, mem_in_b))\\\\nValueError: current limit exceeds maximum limit\\\\n\\', \\'exitcode\\': 1, \\'configuration_origin\\': \\'DUMMY\\'}.',)"
     ]
    }
   ],
   "source": [
    "model = AutoSklearnRegressor(\n",
    "    time_left_for_this_task=180,\n",
    "    per_run_time_limit=30,\n",
    "    n_jobs=1\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "joblib.dump(automl, f\"best_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
